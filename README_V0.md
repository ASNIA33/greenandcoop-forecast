# ğŸŒ¤ï¸ Forecast 2.0 - Pipeline de DonnÃ©es MÃ©tÃ©orologiques

[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/)
[![MongoDB](https://img.shields.io/badge/MongoDB-Atlas-green.svg)](https://www.mongodb.com/atlas)
[![AWS](https://img.shields.io/badge/AWS-ECS%20Fargate-orange.svg)](https://aws.amazon.com/ecs/)
[![Docker](https://img.shields.io/badge/Docker-Compose-blue.svg)](https://www.docker.com/)

## ğŸ“‹ Table des matiÃ¨res

1. [Contexte du projet](#contexte-du-projet)
2. [Architecture technique](#architecture-technique)
3. [Justifications techniques](#justifications-techniques)
4. [SchÃ©ma de la base de donnÃ©es](#schema-de-la-base-de-donnees)
5. [Logigramme du processus ETL](#logigramme-du-processus-etl)
6. [Stack technique](#stack-technique)
7. [Guide de dÃ©ploiement](#guide-de-deploiement)
8. [Reporting et mÃ©triques](#reporting-et-metriques)
9. [Structure du projet](#structure-du-projet)

---

## ğŸ¯ Contexte du projet 

### L'entreprise

**GreenAndCoop** est un fournisseur coopÃ©ratif franÃ§ais d'Ã©lectricitÃ© d'origine renouvelable dans les Hauts-de-France.

### Le besoin mÃ©tier

Pour optimiser ses prÃ©visions de demande d'Ã©lectricitÃ©, GreenAndCoop a lancÃ© le projet **Forecast 2.0** avec les objectifs suivants :

| Objectif                    | Description                                                                         |
| --------------------------- | ----------------------------------------------------------------------------------- |
| **Ã‰quilibrer le rÃ©seau**    | Assurer l'Ã©quilibre production/consommation en temps rÃ©el pour Ã©viter les pÃ©nalitÃ©s |
| **Optimiser la production** | Planifier l'utilisation des sources renouvelables (solaire, Ã©olien)                 |
| **GÃ©rer les coÃ»ts**         | RÃ©duire les achats d'urgence sur le marchÃ© de gros                                  |

### Mission Data Engineer

IntÃ©grer de nouvelles sources de donnÃ©es mÃ©tÃ©orologiques (stations semi-professionnelles) dans un pipeline fiable pour alimenter les modÃ¨les de prÃ©vision des Data Scientists.

### Sources de donnÃ©es

| Source              | Type             | Localisation      | Format        |
| ------------------- | ---------------- | ----------------- | ------------- |
| Weather Underground | Station amateur  | La Madeleine (FR) | Excel â†’ JSONL |
| Weather Underground | Station amateur  | Ichtegem (BE)     | Excel â†’ JSONL |
| InfoClimat          | RÃ©seau open-data | Hauts-de-France   | JSON â†’ JSONL  |

---

## ğŸ—ï¸ Architecture technique

### Architecture globale

```mermaid
flowchart TB
    subgraph SOURCES["ğŸ“¡ Sources de donnÃ©es"]
        WU1["ğŸŒ¡ï¸ Weather Underground<br/>La Madeleine (FR)"]
        WU2["ğŸŒ¡ï¸ Weather Underground<br/>Ichtegem (BE)"]
        IC["ğŸŒ InfoClimat<br/>RÃ©seau Hauts-de-France"]
    end

    subgraph INGESTION["ğŸ“¥ Ingestion (Airbyte)"]
        AB["âš™ï¸ Airbyte<br/>Connecteurs Excel/JSON"]
    end

    subgraph STOCKAGE_RAW["â˜ï¸ Stockage brut (AWS S3)"]
        S3["ğŸ“¦ S3 Bucket<br/>greenandcoop-forecast-raw-data"]
    end

    subgraph ETL["ğŸ”„ Pipeline ETL (AWS ECS)"]
        ECS["ğŸ³ ECS Fargate<br/>Container Python"]

        subgraph PROCESSING["Traitement"]
            EX["1ï¸âƒ£ Extraction<br/>s3_connector.py"]
            TR["2ï¸âƒ£ Transformation<br/>cleaner.py"]
            VA["3ï¸âƒ£ Validation<br/>validator.py"]
            LO["4ï¸âƒ£ Chargement<br/>mongo_connector.py"]
        end
    end

    subgraph STOCKAGE_FINAL["ğŸ—„ï¸ Base de donnÃ©es (MongoDB Atlas)"]
        ATLAS["ğŸƒ MongoDB Atlas<br/>ReplicaSet M0"]

        subgraph COLLECTIONS["Collections"]
            MEAS["ğŸ“Š measurements<br/>3807 documents"]
            STAT["ğŸ“ stations<br/>4 documents"]
        end
    end

    subgraph MONITORING["ğŸ“ˆ Monitoring (AWS CloudWatch)"]
        CW["ğŸ“‹ CloudWatch Logs<br/>/ecs/forecast-etl"]
    end

    subgraph CONSUMERS["ğŸ‘¥ Consommateurs"]
        DS["ğŸ§ª Data Scientists<br/>SageMaker"]
    end

    WU1 --> AB
    WU2 --> AB
    IC --> AB
    AB --> S3
    S3 --> ECS
    ECS --> EX --> TR --> VA --> LO
    LO --> ATLAS
    ATLAS --> MEAS
    ATLAS --> STAT
    ECS --> CW
    ATLAS --> DS
```

### Architecture de dÃ©ploiement AWS

```mermaid
flowchart TB
    subgraph AWS["â˜ï¸ AWS Cloud (eu-west-3)"]
        subgraph VPC["ğŸ”’ VPC"]
            subgraph SUBNET["Subnet Public"]
                ECS["ğŸ³ ECS Fargate<br/>Task: forecast-etl<br/>0.5 vCPU / 1 GB RAM"]
            end
        end

        subgraph S3_SERVICE["S3"]
            S3["ğŸ“¦ greenandcoop-forecast-raw-data"]
        end

        subgraph ECR_SERVICE["ECR"]
            ECR["ğŸ‹ forecast-etl:latest"]
        end

        subgraph CW_SERVICE["CloudWatch"]
            CW["ğŸ“‹ /ecs/forecast-etl"]
        end

        subgraph IAM_SERVICE["IAM"]
            ROLE1["ğŸ”‘ ecsTaskExecutionRole"]
            ROLE2["ğŸ”‘ forecast-etl-task-role"]
        end
    end

    subgraph ATLAS["ğŸŒ MongoDB Atlas"]
        CLUSTER["ğŸƒ forecast-cluster<br/>ReplicaSet 3 nÅ“uds<br/>Region: eu-west-3"]
    end

    ECR --> ECS
    ECS --> S3
    ECS --> ATLAS
    ECS --> CW
    ROLE1 --> ECS
    ROLE2 --> ECS
```

### Architecture MongoDB Atlas (ReplicaSet)

```mermaid
flowchart LR
    subgraph ATLAS["MongoDB Atlas - forecast-cluster"]
        subgraph RS["ReplicaSet rs0"]
            P["ğŸŸ¢ PRIMARY<br/>ac-r67aepk-shard-00-00<br/>Lectures/Ã‰critures"]
            S1["ğŸ”µ SECONDARY<br/>ac-r67aepk-shard-00-01<br/>RÃ©plication"]
            S2["ğŸ”µ SECONDARY<br/>ac-r67aepk-shard-00-02<br/>RÃ©plication"]
        end
    end

    APP["ğŸ³ ECS Container"] --> P
    P -->|"RÃ©plication<br/>asynchrone"| S1
    P -->|"RÃ©plication<br/>asynchrone"| S2

    S1 -.->|"Failover<br/>automatique"| P
    S2 -.->|"Failover<br/>automatique"| P
```

---

## ğŸ’¡ Justifications techniques

### Pourquoi MongoDB Atlas plutÃ´t que MongoDB sur ECS ?

| CritÃ¨re                    | MongoDB sur ECS (Self-hosted)                                     | MongoDB Atlas (ManagÃ©)                      |
| -------------------------- | ----------------------------------------------------------------- | ------------------------------------------- |
| **ReplicaSet**             | âŒ TrÃ¨s complexe Ã  configurer (IPs dynamiques, Service Discovery) | âœ… Inclus et gÃ©rÃ© automatiquement           |
| **Haute disponibilitÃ©**    | âŒ Configuration manuelle du failover                             | âœ… Failover automatique en ~30s             |
| **SÃ©curitÃ©**               | âš ï¸ Gestion manuelle (KeyFile, TLS)                                | âœ… Chiffrement at-rest et in-transit inclus |
| **Sauvegardes**            | âŒ Ã€ implÃ©menter (scripts, S3)                                    | âœ… Snapshots automatiques inclus            |
| **Monitoring**             | âŒ Ã€ configurer (Prometheus, Grafana)                             | âœ… Dashboard intÃ©grÃ© avec alertes           |
| **CoÃ»t (petit volume)**    | ~$30-50/mois (3 instances EC2)                                    | âœ… **Gratuit** (M0 Free Tier)               |
| **Maintenance**            | âŒ Patches, upgrades manuels                                      | âœ… Automatique                              |
| **Temps de mise en place** | ~2-3 jours                                                        | ~10 minutes                                 |

**Conclusion** : Pour un projet d'Ã©tude avec un faible volume de donnÃ©es (~1.7 Mo), MongoDB Atlas M0 offre toutes les fonctionnalitÃ©s d'un ReplicaSet de production **gratuitement**, sans la complexitÃ© opÃ©rationnelle.

### Pourquoi ECS Fargate ?

| CritÃ¨re                 | EC2                              | ECS Fargate                       |
| ----------------------- | -------------------------------- | --------------------------------- |
| **Gestion serveurs**    | âŒ Provisioning, patches         | âœ… Serverless                     |
| **Scaling**             | âš ï¸ Manuel ou Auto Scaling Groups | âœ… Automatique                    |
| **CoÃ»t (job ponctuel)** | ~$0.50/heure (instance allumÃ©e)  | âœ… ~$0.01/exÃ©cution (pay-per-use) |
| **ComplexitÃ©**          | âš ï¸ AMI, Security Groups, etc.    | âœ… Juste une Task Definition      |

**Conclusion** : Pour un job ETL ponctuel qui s'exÃ©cute en ~1 seconde, Fargate est idÃ©al (on ne paie que le temps d'exÃ©cution).

### Pourquoi Airbyte pour l'ingestion ?

| CritÃ¨re            | Scripts manuels   | Airbyte                      |
| ------------------ | ----------------- | ---------------------------- |
| **Connecteurs**    | âŒ Ã€ dÃ©velopper   | âœ… 300+ connecteurs prÃªts    |
| **Transformation** | âŒ Code custom    | âœ… Normalisation automatique |
| **Monitoring**     | âŒ Ã€ implÃ©menter  | âœ… UI avec historique        |
| **Orchestration**  | âŒ Cron + scripts | âœ… Scheduling intÃ©grÃ©        |

---

## ğŸ—„ï¸ SchÃ©ma de la base de donnÃ©es

### Vue d'ensemble

```mermaid
erDiagram
    MEASUREMENTS {
        ObjectId _id PK
        string station_id FK
        string station_name
        datetime timestamp
        float temperature_celsius
        float humidity_percent
        float wind_speed_kmh
        float pressure_hpa
        float latitude
        float longitude
    }

    STATIONS {
        ObjectId _id PK
        string station_id UK
        string station_name
        float latitude
        float longitude
        int elevation
        string type
        object license
        datetime timestamp
    }

    STATIONS ||--o{ MEASUREMENTS : "1:N"
```

### Collection `measurements` (3807 documents)

Stocke les relevÃ©s mÃ©tÃ©orologiques des stations.

```json
{
  "_id": "ObjectId('694c043e8a0415f138a07009')",
  "station_id": "IICHTE19",
  "station_name": "WeerstationBS",
  "timestamp": "2025-12-24T00:04:00.000+00:00",
  "temperature_celsius": 13.78,
  "humidity_percent": 87,
  "wind_speed_kmh": 13.2,
  "pressure_hpa": 998.3,
  "latitude": 51.092,
  "longitude": 2.999
}
```

| Champ                 | Type     | Description                      | Validation |
| --------------------- | -------- | -------------------------------- | ---------- |
| `station_id`          | String   | Identifiant unique de la station | Requis     |
| `station_name`        | String   | Nom de la station                | Optionnel  |
| `timestamp`           | DateTime | Date/heure du relevÃ©             | Requis     |
| `temperature_celsius` | Float    | TempÃ©rature en Â°C                | -60 Ã  +60  |
| `humidity_percent`    | Float    | HumiditÃ© relative                | 0 Ã  100    |
| `wind_speed_kmh`      | Float    | Vitesse du vent                  | â‰¥ 0        |
| `pressure_hpa`        | Float    | Pression atmosphÃ©rique           | 800 Ã  1200 |
| `latitude`            | Float    | Latitude GPS                     | Optionnel  |
| `longitude`           | Float    | Longitude GPS                    | Optionnel  |

### Collection `stations` (4 documents)

Stocke les mÃ©tadonnÃ©es des stations mÃ©tÃ©orologiques.

```json
{
  "_id": "ObjectId('694c043e8a0415f138a07ee8')",
  "station_id": "00052",
  "station_name": "ArmentiÃ¨res",
  "latitude": 50.689,
  "longitude": 2.877,
  "elevation": 16,
  "type": "static",
  "license": { "name": "ODbL", "url": "..." },
  "timestamp": "2025-12-24T15:18:22.043+00:00"
}
```

### Index crÃ©Ã©s

```javascript
// Collection measurements - Index composÃ© pour requÃªtes temporelles par station
db.measurements.createIndex(
  { station_id: 1, timestamp: 1 },
  { name: "unique_station_timestamp" }
);

// Collection stations - Index unique sur l'identifiant
db.stations.createIndex(
  { station_id: 1 },
  { unique: true, name: "unique_station_id" }
);
```

---

## ğŸ“Š Logigramme du processus ETL

### Processus global

```mermaid
flowchart TD
    START([ğŸš€ DÃ‰BUT]) --> INIT["Initialisation<br/>Chargement .env"]

    INIT --> CHECK_ENV{{"Variables<br/>d'environnement<br/>valides ?"}}
    CHECK_ENV -->|Non| ERROR_ENV[/"âŒ ERREUR :<br/>Configuration manquante"/]
    ERROR_ENV --> END_ERROR([ğŸ”´ FIN - Ã‰chec])

    CHECK_ENV -->|Oui| STEP1["ğŸ“¥ Ã‰TAPE 1 : EXTRACTION<br/>Connexion Ã  S3"]

    STEP1 --> S3_CONNECT{{"Connexion S3<br/>rÃ©ussie ?"}}
    S3_CONNECT -->|Non| ERROR_S3[/"âŒ ERREUR :<br/>AccÃ¨s S3 refusÃ©"/]
    ERROR_S3 --> END_ERROR

    S3_CONNECT -->|Oui| DOWNLOAD["TÃ©lÃ©chargement des fichiers<br/>vers data/downloaded/"]

    DOWNLOAD --> FILES_EXIST{{"Fichiers<br/>trouvÃ©s ?"}}
    FILES_EXIST -->|Non| WARN_EMPTY[/"âš ï¸ AVERTISSEMENT :<br/>Bucket vide"/]
    WARN_EMPTY --> END_WARN([ğŸŸ¡ FIN - Aucune donnÃ©e])

    FILES_EXIST -->|Oui| STEP2["ğŸ”„ Ã‰TAPE 2 : TRANSFORMATION"]

    STEP2 --> LOOP_START{{"Pour chaque<br/>fichier"}}

    LOOP_START --> DETECT_TYPE{{"Type de<br/>fichier ?"}}

    DETECT_TYPE -->|"station_*.jsonl"| TRANSFORM_WEATHER["Transformation mÃ©tÃ©o<br/>â€¢ Mapping colonnes<br/>â€¢ Â°F â†’ Â°C<br/>â€¢ mph â†’ km/h<br/>â€¢ inHg â†’ hPa"]

    DETECT_TYPE -->|"*info_climat*"| TRANSFORM_STATION["Transformation stations<br/>â€¢ Extraction mÃ©tadonnÃ©es<br/>â€¢ Normalisation coords"]

    TRANSFORM_WEATHER --> VALIDATE["ğŸ” Validation Pydantic<br/>â€¢ Limites tempÃ©rature<br/>â€¢ Limites humiditÃ©<br/>â€¢ Types de donnÃ©es"]

    TRANSFORM_STATION --> STORE_STATIONS[("ğŸ’¾ Stockage temporaire<br/>stations_data[]")]

    VALIDATE --> VALID_CHECK{{"DonnÃ©es<br/>valides ?"}}
    VALID_CHECK -->|Oui| STORE_MEASURES[("ğŸ’¾ Stockage temporaire<br/>measurements_data[]")]
    VALID_CHECK -->|Non| LOG_REJECT[/"ğŸ“ LOG :<br/>Motif de rejet"/]
    LOG_REJECT --> STORE_MEASURES

    STORE_MEASURES --> LOOP_END{{"Autres<br/>fichiers ?"}}
    STORE_STATIONS --> LOOP_END
    LOOP_END -->|Oui| LOOP_START

    LOOP_END -->|Non| STEP3["ğŸ“¤ Ã‰TAPE 3 : CHARGEMENT"]

    STEP3 --> MONGO_CONNECT["Connexion MongoDB Atlas"]

    MONGO_CONNECT --> MONGO_OK{{"Connexion<br/>rÃ©ussie ?"}}
    MONGO_OK -->|Non| ERROR_MONGO[/"âŒ ERREUR :<br/>Timeout MongoDB"/]
    ERROR_MONGO --> END_ERROR

    MONGO_OK -->|Oui| CREATE_INDEX["CrÃ©ation/VÃ©rification<br/>des index"]

    CREATE_INDEX --> INSERT_MEAS["Insertion measurements<br/>ordered=False<br/>(gestion doublons)"]

    INSERT_MEAS --> INSERT_STAT["Insertion stations<br/>ordered=False<br/>(gestion doublons)"]

    INSERT_STAT --> CLOSE_CONN["Fermeture connexion"]

    CLOSE_CONN --> LOG_SUCCESS[/"ğŸ“ LOG :<br/>Pipeline terminÃ© avec succÃ¨s"/]

    LOG_SUCCESS --> END_SUCCESS([ğŸŸ¢ FIN - SuccÃ¨s])
```

### LÃ©gende des symboles

| Symbole               | Signification                   |
| --------------------- | ------------------------------- |
| â¬­ (Rectangle arrondi) | DÃ©but / Fin                     |
| â–­ (Rectangle)         | Processus / Action              |
| â—‡ (Losange)           | DÃ©cision / Condition            |
| â–± (ParallÃ©logramme)   | EntrÃ©e / Sortie (logs, erreurs) |
| âŒ“ (Cylindre)          | Stockage de donnÃ©es             |

---

## ğŸ› ï¸ Stack technique

### Langages et frameworks

| Outil    | Version | Usage                    |
| -------- | ------- | ------------------------ |
| Python   | 3.12    | Langage principal        |
| Pydantic | 2.x     | Validation des donnÃ©es   |
| PyMongo  | 4.x     | Driver MongoDB           |
| Boto3    | 1.x     | SDK AWS (S3)             |
| Pandas   | 2.x     | Manipulation des donnÃ©es |

### Infrastructure

| Service             | Usage                   | Justification                      |
| ------------------- | ----------------------- | ---------------------------------- |
| **AWS S3**          | Stockage donnÃ©es brutes | Scalable, durable, intÃ©grÃ© Airbyte |
| **AWS ECS Fargate** | ExÃ©cution du pipeline   | Serverless, pay-per-use            |
| **AWS ECR**         | Registry Docker         | IntÃ©grÃ© ECS, sÃ©curisÃ©              |
| **AWS CloudWatch**  | Logs et monitoring      | Natif AWS, temps rÃ©el              |
| **MongoDB Atlas**   | Base de donnÃ©es         | ReplicaSet gratuit, managÃ©         |
| **Airbyte**         | Ingestion des donnÃ©es   | Connecteurs prÃªts Ã  l'emploi       |

### Outils de dÃ©veloppement

| Outil                   | Usage                         |
| ----------------------- | ----------------------------- |
| Docker / Docker Compose | Conteneurisation et dev local |
| pytest                  | Tests unitaires               |
| Git                     | Versioning                    |

---

## ğŸš€ Guide de dÃ©ploiement

### PrÃ©requis

- Compte AWS avec droits ECS, ECR, S3, IAM, CloudWatch
- Compte MongoDB Atlas (gratuit)
- Docker Desktop installÃ©
- AWS CLI configurÃ© (`aws configure`)
- Python 3.12+

### Ã‰tape 1 : Configuration MongoDB Atlas

1. CrÃ©er un cluster M0 (gratuit) sur [MongoDB Atlas](https://cloud.mongodb.com)
2. RÃ©gion : `AWS eu-west-3` (Paris)
3. CrÃ©er un utilisateur `forecast_user` avec droits Read/Write
4. Network Access : Ajouter `0.0.0.0/0` (ou les IPs ECS)
5. RÃ©cupÃ©rer l'URI de connexion

### Ã‰tape 2 : PrÃ©paration de l'image Docker

```bash
# Build de l'image
docker build --platform linux/amd64 -t forecast-etl .

# Tag pour ECR
docker tag forecast-etl:latest <ACCOUNT_ID>.dkr.ecr.eu-west-3.amazonaws.com/forecast-etl:latest

# Login ECR
aws ecr get-login-password --region eu-west-3 | docker login --username AWS --password-stdin <ACCOUNT_ID>.dkr.ecr.eu-west-3.amazonaws.com

# Push
docker push <ACCOUNT_ID>.dkr.ecr.eu-west-3.amazonaws.com/forecast-etl:latest
```

### Ã‰tape 3 : DÃ©ploiement ECS

```bash
# CrÃ©er les rÃ´les IAM (si nÃ©cessaire)
aws iam create-role --role-name ecsTaskExecutionRole --assume-role-policy-document file://trust-policy.json
aws iam create-role --role-name forecast-etl-task-role --assume-role-policy-document file://trust-policy.json

# CrÃ©er le Log Group
aws logs create-log-group --log-group-name /ecs/forecast-etl --region eu-west-3

# Enregistrer la Task Definition
aws ecs register-task-definition --cli-input-json file://task-definition.json --region eu-west-3

# ExÃ©cuter la Task
aws ecs run-task \
    --cluster greenandcoop-cluster \
    --task-definition forecast-etl \
    --launch-type FARGATE \
    --network-configuration "awsvpcConfiguration={subnets=[subnet-xxx],securityGroups=[sg-xxx],assignPublicIp=ENABLED}" \
    --region eu-west-3
```

### Ã‰tape 4 : VÃ©rification

```bash
# Suivre les logs en temps rÃ©el
aws logs tail /ecs/forecast-etl --follow --region eu-west-3
```

RÃ©sultat attendu :

```
INFO - -- DÃ©but du pipeline du projet Forecast 2.0. --
INFO - [Etape 1/3] : CONNEXION A S3 et RECUPERATION DES FICHIERS...
INFO - SuccÃ¨s : 3 fichiers telechargÃ©s depuis S3
INFO - [Etape 2/3] : NETTOYAGE ET TRANSFORMATION DES DONNEES...
INFO - Total prÃªt : 3811 documents.
INFO - [Etape 3/3] : INSERTION DES DONNES DANS MONGODB...
INFO - MongoConnector initialisÃ© en mode: Atlas
INFO - Connexion rÃ©ussie (Atlas) Ã  la base 'greenandcoop_weather'
INFO - -> SuccÃ¨s : 3807 documents insÃ©rÃ©s dans 'measurements'.
INFO - -> SuccÃ¨s : 4 documents insÃ©rÃ©s dans 'stations'.
INFO - === Pipeline terminÃ© avec succÃ¨s ! ===
```

---

## ğŸ“ˆ Reporting et mÃ©triques

### Temps d'exÃ©cution du pipeline

| Ã‰tape              | DurÃ©e     | Performance  |
| ------------------ | --------- | ------------ |
| Extraction S3      | ~0.6s     | âœ… Excellent |
| Transformation     | ~0.3s     | âœ… Excellent |
| Connexion MongoDB  | ~0.2s     | âœ… Excellent |
| Insertion donnÃ©es  | ~0.1s     | âœ… Excellent |
| **Total pipeline** | **~1.2s** | âœ… Excellent |

### QualitÃ© des donnÃ©es

| MÃ©trique          | Valeur | Seuil | Statut |
| ----------------- | ------ | ----- | ------ |
| Documents traitÃ©s | 3811   | -     | -      |
| Documents valides | 3811   | -     | -      |
| Documents rejetÃ©s | 0      | <1%   | âœ…     |
| **Taux d'erreur** | **0%** | <1%   | âœ…     |

### Temps d'accessibilitÃ© (MongoDB Atlas)

| RequÃªte                           | Temps | Seuil  | Statut |
| --------------------------------- | ----- | ------ | ------ |
| Lecture unitaire (dernier relevÃ©) | ~2ms  | <50ms  | âœ…     |
| AgrÃ©gation (moyenne tempÃ©rature)  | ~15ms | <100ms | âœ…     |

### Scripts de reporting

```bash
# Mesurer la performance (depuis le conteneur ou en local)
python -m src.reporting.check_performance

# VÃ©rifier la qualitÃ© des donnÃ©es
python -m src.reporting.check_quality

# Tester la rÃ©plication (environnement local uniquement)
python -m src.reporting.test_replication
```

---

## ğŸ“ Structure du projet

```
greenandcoop-forecast/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                    # Ce fichier
â”œâ”€â”€ ğŸ“„ Dockerfile                   # Image Docker du pipeline
â”œâ”€â”€ ğŸ“„ docker-compose.yml           # Environnement local (ReplicaSet)
â”œâ”€â”€ ğŸ“„ requirements.txt             # DÃ©pendances Python
â”‚
â”œâ”€â”€ ğŸ“ config/
â”‚   â””â”€â”€ ğŸ“„ .env                     # Variables d'environnement
â”‚
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”œâ”€â”€ ğŸ“„ main.py                  # Point d'entrÃ©e du pipeline
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ connectors/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ s3_connector.py      # Connexion AWS S3
â”‚   â”‚   â””â”€â”€ ğŸ“„ mongo_connector.py   # Connexion MongoDB (Atlas/Local)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ processing/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ cleaner.py           # Transformation des donnÃ©es
â”‚   â”‚   â””â”€â”€ ğŸ“„ validator.py         # Validation Pydantic
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ reporting/
â”‚       â”œâ”€â”€ ğŸ“„ check_performance.py # Mesure temps d'accÃ¨s
â”‚       â”œâ”€â”€ ğŸ“„ check_quality.py     # Audit qualitÃ© donnÃ©es
â”‚       â””â”€â”€ ğŸ“„ test_replication.py  # Test rÃ©plication (local)
â”‚
â”œâ”€â”€ ğŸ“ tests/
â”‚   â””â”€â”€ ğŸ“„ test_quality.py          # Tests unitaires pytest
â”‚
â”œâ”€â”€ ğŸ“ docs/
â”‚   â”œâ”€â”€ ğŸ“„ TRANSFORMATION_LOGIC.md  # Logique de transformation
â”‚   â”œâ”€â”€ ğŸ“„ MIGRATION_LOGIC.md       # Logique de migration
â”‚   â””â”€â”€ ğŸ“ diagrams/                # Diagrammes exportÃ©s
â”‚
â”œâ”€â”€ ğŸ“ ecs-deployment/              # Fichiers dÃ©ploiement AWS
â”‚   â”œâ”€â”€ ğŸ“„ task-definition.json
â”‚   â”œâ”€â”€ ğŸ“„ trust-policy.json
â”‚   â””â”€â”€ ğŸ“„ s3-access-policy.json
â”‚
â””â”€â”€ ğŸ“ logs/                        # Logs locaux
    â””â”€â”€ ğŸ“„ pipeline.log
```

---

## ğŸ“ Contact

**Projet** : Forecast 2.0 - GreenAndCoop  
**Data Engineer** : Abd Selam M'BODJ  
**Date** : DÃ©cembre 2025

---

## ğŸ“š Documentation complÃ©mentaire

- [Logique de transformation](docs/TRANSFORMATION_LOGIC.md)
- [Logique de migration](docs/MIGRATION_LOGIC.md)
- [AWS ECS Documentation](https://docs.aws.amazon.com/ecs/)
- [MongoDB Atlas Documentation](https://docs.atlas.mongodb.com/)
