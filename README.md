# ğŸŒ¤ï¸ Forecast 2.0 - Pipeline de DonnÃ©es MÃ©tÃ©orologiques

[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/)
[![MongoDB](https://img.shields.io/badge/MongoDB-Atlas-green.svg)](https://www.mongodb.com/atlas)
[![AWS](https://img.shields.io/badge/AWS-ECS%20Fargate-orange.svg)](https://aws.amazon.com/ecs/)
[![Docker](https://img.shields.io/badge/Docker-Compose-blue.svg)](https://www.docker.com/)

## ğŸ“‹ Table des matiÃ¨res

1. [Contexte du projet](#-contexte-du-projet)
2. [Architecture technique](#-architecture-technique)
3. [Justifications techniques](#-justifications-techniques)
4. [SchÃ©ma de la base de donnÃ©es](#-schÃ©ma-de-la-base-de-donnÃ©es)
5. [Logigramme du processus ETL](#-logigramme-du-processus-etl)
6. [Stack technique](#-stack-technique)
7. [Guide de dÃ©ploiement](#-guide-de-dÃ©ploiement)
8. [Reporting et mÃ©triques](#-reporting-et-mÃ©triques)
9. [Structure du projet](#-structure-du-projet)

---

## ğŸ¯ Contexte du projet

### L'entreprise

**GreenAndCoop** est un fournisseur coopÃ©ratif franÃ§ais d'Ã©lectricitÃ© d'origine renouvelable dans les Hauts-de-France.

### Le besoin mÃ©tier

Pour optimiser ses prÃ©visions de demande d'Ã©lectricitÃ©, GreenAndCoop a lancÃ© le projet **Forecast 2.0** avec les objectifs suivants :

| Objectif | Description |
|----------|-------------|
| **Ã‰quilibrer le rÃ©seau** | Assurer l'Ã©quilibre production/consommation en temps rÃ©el pour Ã©viter les pÃ©nalitÃ©s |
| **Optimiser la production** | Planifier l'utilisation des sources renouvelables (solaire, Ã©olien) |
| **GÃ©rer les coÃ»ts** | RÃ©duire les achats d'urgence sur le marchÃ© de gros |

### Mission Data Engineer

IntÃ©grer de nouvelles sources de donnÃ©es mÃ©tÃ©orologiques (stations semi-professionnelles) dans un pipeline fiable pour alimenter les modÃ¨les de prÃ©vision des Data Scientists.

### Sources de donnÃ©es

| Source | Type | Localisation | Format |
|--------|------|--------------|--------|
| Weather Underground | Station amateur | La Madeleine (FR) | Excel â†’ JSONL |
| Weather Underground | Station amateur | Ichtegem (BE) | Excel â†’ JSONL |
| InfoClimat | RÃ©seau open-data | Hauts-de-France | JSON â†’ JSONL |

---

## ğŸ—ï¸ Architecture technique

### Architecture globale

```mermaid
flowchart TB
    subgraph SOURCES["ğŸ“¡ Sources de donnÃ©es"]
        WU1["ğŸŒ¡ï¸ Weather Underground<br/>La Madeleine (FR)"]
        WU2["ğŸŒ¡ï¸ Weather Underground<br/>Ichtegem (BE)"]
        IC["ğŸŒ InfoClimat<br/>RÃ©seau Hauts-de-France"]
    end

    subgraph INGESTION["ğŸ“¥ Ingestion (Airbyte)"]
        AB["âš™ï¸ Airbyte<br/>Connecteurs Excel/JSON"]
    end

    subgraph STOCKAGE_RAW["â˜ï¸ Stockage brut (AWS S3)"]
        S3["ğŸ“¦ S3 Bucket<br/>greenandcoop-forecast-raw-data"]
    end

    subgraph ETL["ğŸ”„ Pipeline ETL (AWS ECS)"]
        ECS["ğŸ³ ECS Fargate<br/>Container Python"]
        
        subgraph PROCESSING["Traitement"]
            EX["1ï¸âƒ£ Extraction<br/>s3_connector.py"]
            TR["2ï¸âƒ£ Transformation<br/>cleaner.py"]
            VA["3ï¸âƒ£ Validation<br/>validator.py"]
            LO["4ï¸âƒ£ Chargement<br/>mongo_connector.py"]
        end
    end

    subgraph STOCKAGE_FINAL["ğŸ—„ï¸ Base de donnÃ©es (MongoDB Atlas)"]
        ATLAS["ğŸƒ MongoDB Atlas<br/>ReplicaSet M0"]
        
        subgraph COLLECTIONS["Collection unifiÃ©e"]
            WD["ğŸ“Š weather_data<br/>3811 documents"]
        end
    end

    subgraph MONITORING["ğŸ“ˆ Monitoring (AWS CloudWatch)"]
        CW["ğŸ“‹ CloudWatch Logs<br/>/ecs/forecast-etl"]
    end

    subgraph CONSUMERS["ğŸ‘¥ Consommateurs"]
        DS["ğŸ§ª Data Scientists<br/>SageMaker"]
    end

    WU1 --> AB
    WU2 --> AB
    IC --> AB
    AB --> S3
    S3 --> ECS
    ECS --> EX --> TR --> VA --> LO
    LO --> ATLAS
    ATLAS --> WD
    ECS --> CW
    ATLAS --> DS
```

### Architecture de dÃ©ploiement AWS

```mermaid
flowchart TB
    subgraph AWS["â˜ï¸ AWS Cloud (eu-west-3)"]
        subgraph VPC["ğŸ”’ VPC"]
            subgraph SUBNET["Subnet Public"]
                ECS["ğŸ³ ECS Fargate<br/>Task: forecast-etl<br/>0.5 vCPU / 1 GB RAM"]
            end
        end
        
        subgraph S3_SERVICE["S3"]
            S3["ğŸ“¦ greenandcoop-forecast-raw-data"]
        end
        
        subgraph ECR_SERVICE["ECR"]
            ECR["ğŸ‹ forecast-etl:latest"]
        end
        
        subgraph CW_SERVICE["CloudWatch"]
            CW["ğŸ“‹ /ecs/forecast-etl"]
        end
        
        subgraph IAM_SERVICE["IAM"]
            ROLE1["ğŸ”‘ ecsTaskExecutionRole"]
            ROLE2["ğŸ”‘ forecast-etl-task-role"]
        end
    end

    subgraph ATLAS["ğŸŒ MongoDB Atlas"]
        CLUSTER["ğŸƒ forecast-cluster<br/>ReplicaSet 3 nÅ“uds<br/>Region: eu-west-3"]
    end

    ECR --> ECS
    S3 -->|"Lecture<br/>donnÃ©es brutes"| ECS
    ECS -->|"Ã‰criture<br/>donnÃ©es traitÃ©es"| ATLAS
    ECS --> CW
    ROLE1 --> ECS
    ROLE2 --> ECS
```

### Architecture MongoDB Atlas (ReplicaSet)

```mermaid
flowchart LR
    subgraph ATLAS["MongoDB Atlas - forecast-cluster"]
        subgraph RS["ReplicaSet rs0"]
            P["ğŸŸ¢ PRIMARY<br/>ac-r67aepk-shard-00-00<br/>Lectures/Ã‰critures"]
            S1["ğŸ”µ SECONDARY<br/>ac-r67aepk-shard-00-01<br/>RÃ©plication"]
            S2["ğŸ”µ SECONDARY<br/>ac-r67aepk-shard-00-02<br/>RÃ©plication"]
        end
    end

    APP["ğŸ³ ECS Container"] --> P
    P -->|"RÃ©plication<br/>asynchrone"| S1
    P -->|"RÃ©plication<br/>asynchrone"| S2
    
    S1 -.->|"Failover<br/>automatique"| P
    S2 -.->|"Failover<br/>automatique"| P
```

---

## ğŸ’¡ Justifications techniques

### Pourquoi MongoDB Atlas plutÃ´t que MongoDB sur ECS ?

| CritÃ¨re | MongoDB sur ECS (Self-hosted) | MongoDB Atlas (ManagÃ©) |
|---------|-------------------------------|------------------------|
| **ReplicaSet** | âŒ TrÃ¨s complexe Ã  configurer (IPs dynamiques, Service Discovery) | âœ… Inclus et gÃ©rÃ© automatiquement |
| **Haute disponibilitÃ©** | âŒ Configuration manuelle du failover | âœ… Failover automatique en ~30s |
| **SÃ©curitÃ©** | âš ï¸ Gestion manuelle (KeyFile, TLS) | âœ… Chiffrement at-rest et in-transit inclus |
| **Sauvegardes** | âŒ Ã€ implÃ©menter (scripts, S3) | âœ… Snapshots automatiques inclus |
| **Monitoring** | âŒ Ã€ configurer (Prometheus, Grafana) | âœ… Dashboard intÃ©grÃ© avec alertes |
| **CoÃ»t (petit volume)** | ~$30-50/mois (3 instances EC2) | âœ… **Gratuit** (M0 Free Tier) |
| **Maintenance** | âŒ Patches, upgrades manuels | âœ… Automatique |
| **Temps de mise en place** | ~2-3 jours | ~10 minutes |

**Conclusion** : Pour un projet d'Ã©tude avec un faible volume de donnÃ©es (~1.7 Mo), MongoDB Atlas M0 offre toutes les fonctionnalitÃ©s d'un ReplicaSet de production **gratuitement**, sans la complexitÃ© opÃ©rationnelle.

### Pourquoi ECS Fargate ?

| CritÃ¨re | EC2 | ECS Fargate |
|---------|-----|-------------|
| **Gestion serveurs** | âŒ Provisioning, patches | âœ… Serverless |
| **Scaling** | âš ï¸ Manuel ou Auto Scaling Groups | âœ… Automatique |
| **CoÃ»t (job ponctuel)** | ~$0.50/heure (instance allumÃ©e) | âœ… ~$0.01/exÃ©cution (pay-per-use) |
| **ComplexitÃ©** | âš ï¸ AMI, Security Groups, etc. | âœ… Juste une Task Definition |

**Conclusion** : Pour un job ETL ponctuel qui s'exÃ©cute en ~1 seconde, Fargate est idÃ©al (on ne paie que le temps d'exÃ©cution).

### Pourquoi une collection unifiÃ©e `weather_data` ?

| CritÃ¨re | 2 collections (measurements + stations) | 1 collection unifiÃ©e (weather_data) |
|---------|----------------------------------------|-------------------------------------|
| **RequÃªtes Data Scientists** | âš ï¸ Jointures nÃ©cessaires ($lookup) | âœ… RequÃªte directe, pas de jointure |
| **Performance** | âš ï¸ $lookup coÃ»teux sur gros volumes | âœ… Lecture directe optimale |
| **SchÃ©ma** | âš ï¸ DonnÃ©es Ã©clatÃ©es | âœ… Documents auto-portants |
| **FlexibilitÃ©** | âš ï¸ 2 schÃ©mas Ã  maintenir | âœ… 1 schÃ©ma avec `record_type` discriminant |

**Conclusion** : MongoDB n'est pas optimisÃ© pour les jointures. Une collection unifiÃ©e avec un champ `record_type` permet des requÃªtes simples et performantes.

### Pourquoi Airbyte pour l'ingestion ?

| CritÃ¨re | Scripts manuels | Airbyte |
|---------|-----------------|---------|
| **Connecteurs** | âŒ Ã€ dÃ©velopper | âœ… 300+ connecteurs prÃªts |
| **Transformation** | âŒ Code custom | âœ… Normalisation automatique |
| **Monitoring** | âŒ Ã€ implÃ©menter | âœ… UI avec historique |
| **Orchestration** | âŒ Cron + scripts | âœ… Scheduling intÃ©grÃ© |

---

## ğŸ—„ï¸ SchÃ©ma de la base de donnÃ©es

### Vue d'ensemble

Le projet utilise une **collection unique `weather_data`** avec un champ discriminant `record_type` pour diffÃ©rencier les types de documents :

| record_type | Description | Nombre |
|-------------|-------------|--------|
| `measurement` | RelevÃ©s mÃ©tÃ©orologiques | 3807 |
| `station_reference` | MÃ©tadonnÃ©es des stations InfoClimat | 4 |

### Diagramme du schÃ©ma unifiÃ©

```mermaid
erDiagram
    WEATHER_DATA {
        ObjectId _id PK
        string record_type "measurement | station_reference"
        string station_id "Identifiant station"
        string station_name "Nom de la station"
        string source "weather_underground | infoclimat"
        object location "Localisation gÃ©ographique"
        datetime timestamp "Date/heure"
        object measurements "Mesures mÃ©tÃ©o (si measurement)"
        object license "Licence (si station_reference)"
    }
    
    LOCATION {
        string city "Ville"
        string country "Pays (FR/BE)"
        float latitude "Latitude GPS"
        float longitude "Longitude GPS"
        int elevation "Altitude (m)"
    }
    
    MEASUREMENTS {
        float temperature_celsius "TempÃ©rature (Â°C)"
        float humidity_percent "HumiditÃ© (%)"
        float wind_speed_kmh "Vent (km/h)"
        float pressure_hpa "Pression (hPa)"
    }
    
    LICENSE {
        string name "Nom licence"
        string url "URL licence"
        string source_url "URL source"
    }
    
    WEATHER_DATA ||--|| LOCATION : "contient"
    WEATHER_DATA ||--o| MEASUREMENTS : "contient (si measurement)"
    WEATHER_DATA ||--o| LICENSE : "contient (si station_reference)"
```

### Document type `measurement` (relevÃ©s mÃ©tÃ©o)

```json
{
    "_id": "ObjectId('...')",
    "record_type": "measurement",
    "station_id": "IICHTE19",
    "station_name": "WeerstationBS",
    "source": "weather_underground",
    "location": {
        "city": "Ichtegem",
        "country": "BE",
        "latitude": 51.092,
        "longitude": 2.999,
        "elevation": 15
    },
    "timestamp": "2025-12-24T00:04:00.000Z",
    "measurements": {
        "temperature_celsius": 13.78,
        "humidity_percent": 87,
        "wind_speed_kmh": 13.2,
        "pressure_hpa": 998.3
    }
}
```

### Document type `station_reference` (mÃ©tadonnÃ©es)

```json
{
    "_id": "ObjectId('...')",
    "record_type": "station_reference",
    "station_id": "00052",
    "station_name": "ArmentiÃ¨res",
    "source": "infoclimat",
    "location": {
        "city": "ArmentiÃ¨res",
        "country": "FR",
        "latitude": 50.689,
        "longitude": 2.877,
        "elevation": 16
    },
    "station_type": "static",
    "license": {
        "name": "CC BY",
        "url": "https://creativecommons.org/licenses/by/2.0/fr/",
        "source_url": "https://www.infoclimat.fr/stations/metadonnees.php?id=00052"
    },
    "timestamp": "2025-12-24T15:18:22.000Z"
}
```

### Validation des donnÃ©es (Pydantic)

| Champ | RÃ¨gle | Motif de rejet |
|-------|-------|----------------|
| `station_id` | Requis, non vide | `station_id: Field required` |
| `timestamp` | Requis, type datetime | `timestamp: Invalid datetime` |
| `temperature_celsius` | -60 â‰¤ T â‰¤ +60 | `temperature_celsius: greater than 60` |
| `humidity_percent` | 0 â‰¤ H â‰¤ 100 | `humidity_percent: greater than 100` |
| `wind_speed_kmh` | â‰¥ 0 | `wind_speed_kmh: less than 0` |
| `pressure_hpa` | 800 â‰¤ P â‰¤ 1200 | `pressure_hpa: less than 800` |
| `latitude` | -90 â‰¤ lat â‰¤ 90 | `latitude: out of range` |
| `longitude` | -180 â‰¤ lng â‰¤ 180 | `longitude: out of range` |

### Index crÃ©Ã©s

```javascript
// Index 1 : Recherche par station et date (requÃªtes temporelles)
db.weather_data.createIndex(
    { "station_id": 1, "timestamp": 1 },
    { name: "idx_station_timestamp" }
)

// Index 2 : Filtrage par type de document
db.weather_data.createIndex(
    { "record_type": 1 },
    { name: "idx_record_type" }
)

// Index 3 : Recherche par source de donnÃ©es
db.weather_data.createIndex(
    { "source": 1 },
    { name: "idx_source" }
)

// Index 4 : UnicitÃ© pour les stations de rÃ©fÃ©rence
db.weather_data.createIndex(
    { "record_type": 1, "station_id": 1, "source": 1 },
    { unique: true, partialFilterExpression: { "record_type": "station_reference" } }
)
```

### RequÃªtes utiles pour les Data Scientists

```javascript
// Toutes les mesures mÃ©tÃ©o
db.weather_data.find({ record_type: "measurement" })

// Mesures d'une station spÃ©cifique
db.weather_data.find({
    record_type: "measurement",
    station_id: "IICHTE19"
})

// Moyenne tempÃ©rature par station
db.weather_data.aggregate([
    { $match: { record_type: "measurement" } },
    { $group: {
        _id: "$station_id",
        avg_temp: { $avg: "$measurements.temperature_celsius" },
        count: { $sum: 1 }
    }}
])

// Toutes les stations de rÃ©fÃ©rence
db.weather_data.find({ record_type: "station_reference" })

// Mesures dans une zone gÃ©ographique
db.weather_data.find({
    record_type: "measurement",
    "location.latitude": { $gte: 50, $lte: 52 },
    "location.longitude": { $gte: 2, $lte: 4 }
})
```

---

## ğŸ“Š Logigramme du processus ETL

### Processus global

```mermaid
flowchart TD
    START([ğŸš€ DÃ‰BUT]) --> INIT["Initialisation<br/>Chargement .env"]
    
    INIT --> CHECK_ENV{{"Variables<br/>d'environnement<br/>valides ?"}}
    CHECK_ENV -->|Non| ERROR_ENV[/"âŒ ERREUR :<br/>Configuration manquante"/]
    ERROR_ENV --> END_ERROR([ğŸ”´ FIN - Ã‰chec])
    
    CHECK_ENV -->|Oui| STEP1["ğŸ“¥ Ã‰TAPE 1 : EXTRACTION<br/>Connexion Ã  S3"]
    
    STEP1 --> S3_CONNECT{{"Connexion S3<br/>rÃ©ussie ?"}}
    S3_CONNECT -->|Non| ERROR_S3[/"âŒ ERREUR :<br/>AccÃ¨s S3 refusÃ©"/]
    ERROR_S3 --> END_ERROR
    
    S3_CONNECT -->|Oui| DOWNLOAD["TÃ©lÃ©chargement des fichiers<br/>vers data/downloaded/"]
    
    DOWNLOAD --> FILES_EXIST{{"Fichiers<br/>trouvÃ©s ?"}}
    FILES_EXIST -->|Non| WARN_EMPTY[/"âš ï¸ AVERTISSEMENT :<br/>Bucket vide"/]
    WARN_EMPTY --> END_WARN([ğŸŸ¡ FIN - Aucune donnÃ©e])
    
    FILES_EXIST -->|Oui| STEP2["ğŸ”„ Ã‰TAPE 2 : TRANSFORMATION"]
    
    STEP2 --> LOOP_START{{"Pour chaque<br/>fichier"}}
    
    LOOP_START --> DETECT_TYPE{{"Type de<br/>fichier ?"}}
    
    DETECT_TYPE -->|"station_*.jsonl"| TRANSFORM_WEATHER["Transformation mÃ©tÃ©o<br/>â€¢ Mapping colonnes<br/>â€¢ Â°F â†’ Â°C, mph â†’ km/h<br/>â€¢ record_type: measurement"]
    
    DETECT_TYPE -->|"*info_climat*"| TRANSFORM_STATION["Transformation stations<br/>â€¢ Extraction mÃ©tadonnÃ©es<br/>â€¢ record_type: station_reference"]
    
    TRANSFORM_WEATHER --> VALIDATE["ğŸ” Validation Pydantic<br/>â€¢ Limites tempÃ©rature<br/>â€¢ Limites humiditÃ©<br/>â€¢ SchÃ©ma unifiÃ©"]
    
    TRANSFORM_STATION --> VALIDATE
    
    VALIDATE --> VALID_CHECK{{"DonnÃ©es<br/>valides ?"}}
    VALID_CHECK -->|Oui| STORE_DATA[("ğŸ’¾ Stockage temporaire<br/>all_documents[]")]
    VALID_CHECK -->|Non| LOG_REJECT[/"ğŸ“ LOG :<br/>Motif de rejet"/]
    LOG_REJECT --> STORE_DATA
    
    STORE_DATA --> LOOP_END{{"Autres<br/>fichiers ?"}}
    LOOP_END -->|Oui| LOOP_START
    
    LOOP_END -->|Non| STEP3["ğŸ“¤ Ã‰TAPE 3 : CHARGEMENT"]
    
    STEP3 --> MONGO_CONNECT["Connexion MongoDB Atlas"]
    
    MONGO_CONNECT --> MONGO_OK{{"Connexion<br/>rÃ©ussie ?"}}
    MONGO_OK -->|Non| ERROR_MONGO[/"âŒ ERREUR :<br/>Timeout MongoDB"/]
    ERROR_MONGO --> END_ERROR
    
    MONGO_OK -->|Oui| CREATE_INDEX["CrÃ©ation/VÃ©rification<br/>des index"]
    
    CREATE_INDEX --> INSERT_DATA["Insertion weather_data<br/>ordered=False<br/>(gestion doublons)"]
    
    INSERT_DATA --> CLOSE_CONN["Fermeture connexion"]
    
    CLOSE_CONN --> LOG_SUCCESS[/"ğŸ“ LOG :<br/>Pipeline terminÃ© avec succÃ¨s"/]
    
    LOG_SUCCESS --> END_SUCCESS([ğŸŸ¢ FIN - SuccÃ¨s])
```

### LÃ©gende des symboles

| Symbole | Signification |
|---------|---------------|
| â¬­ (Rectangle arrondi) | DÃ©but / Fin |
| â–­ (Rectangle) | Processus / Action |
| â—‡ (Losange) | DÃ©cision / Condition |
| â–± (ParallÃ©logramme) | EntrÃ©e / Sortie (logs, erreurs) |
| âŒ“ (Cylindre) | Stockage de donnÃ©es |

---

## ğŸ› ï¸ Stack technique

### Langages et frameworks

| Outil | Version | Usage |
|-------|---------|-------|
| Python | 3.12 | Langage principal |
| Pydantic | 2.x | Validation des donnÃ©es |
| PyMongo | 4.x | Driver MongoDB |
| Boto3 | 1.x | SDK AWS (S3) |
| Pandas | 2.x | Manipulation des donnÃ©es |

### Infrastructure

| Service | Usage | Justification |
|---------|-------|---------------|
| **AWS S3** | Stockage donnÃ©es brutes | Scalable, durable, intÃ©grÃ© Airbyte |
| **AWS ECS Fargate** | ExÃ©cution du pipeline | Serverless, pay-per-use |
| **AWS ECR** | Registry Docker | IntÃ©grÃ© ECS, sÃ©curisÃ© |
| **AWS CloudWatch** | Logs et monitoring | Natif AWS, temps rÃ©el |
| **MongoDB Atlas** | Base de donnÃ©es | ReplicaSet gratuit, managÃ© |
| **Airbyte** | Ingestion des donnÃ©es | Connecteurs prÃªts Ã  l'emploi |

### Outils de dÃ©veloppement

| Outil | Usage |
|-------|-------|
| Docker / Docker Compose | Conteneurisation et dev local |
| pytest | Tests unitaires |
| Git | Versioning |

---

## ğŸš€ Guide de dÃ©ploiement

### PrÃ©requis

- Compte AWS avec droits ECS, ECR, S3, IAM, CloudWatch
- Compte MongoDB Atlas (gratuit)
- Docker Desktop installÃ©
- AWS CLI configurÃ© (`aws configure`)
- Python 3.12+

### Ã‰tape 1 : Configuration MongoDB Atlas

1. CrÃ©er un cluster M0 (gratuit) sur [MongoDB Atlas](https://cloud.mongodb.com)
2. RÃ©gion : `AWS eu-west-3` (Paris)
3. CrÃ©er un utilisateur `forecast_user` avec droits Read/Write
4. Network Access : Ajouter `0.0.0.0/0` (ou les IPs ECS)
5. RÃ©cupÃ©rer l'URI de connexion

### Ã‰tape 2 : PrÃ©paration de l'image Docker

```bash
# Build de l'image
docker build --platform linux/amd64 -t forecast-etl .

# Tag pour ECR
docker tag forecast-etl:latest <ACCOUNT_ID>.dkr.ecr.eu-west-3.amazonaws.com/forecast-etl:latest

# Login ECR
aws ecr get-login-password --region eu-west-3 | docker login --username AWS --password-stdin <ACCOUNT_ID>.dkr.ecr.eu-west-3.amazonaws.com

# Push
docker push <ACCOUNT_ID>.dkr.ecr.eu-west-3.amazonaws.com/forecast-etl:latest
```

### Ã‰tape 3 : DÃ©ploiement ECS

```bash
# CrÃ©er les rÃ´les IAM (si nÃ©cessaire)
aws iam create-role --role-name ecsTaskExecutionRole --assume-role-policy-document file://trust-policy.json
aws iam create-role --role-name forecast-etl-task-role --assume-role-policy-document file://trust-policy.json

# CrÃ©er le Log Group
aws logs create-log-group --log-group-name /ecs/forecast-etl --region eu-west-3

# Enregistrer la Task Definition
aws ecs register-task-definition --cli-input-json file://task-definition.json --region eu-west-3

# ExÃ©cuter la Task
aws ecs run-task \
    --cluster greenandcoop-cluster \
    --task-definition forecast-etl \
    --launch-type FARGATE \
    --network-configuration "awsvpcConfiguration={subnets=[subnet-xxx],securityGroups=[sg-xxx],assignPublicIp=ENABLED}" \
    --region eu-west-3
```

### Ã‰tape 4 : VÃ©rification

```bash
# Suivre les logs en temps rÃ©el
aws logs tail /ecs/forecast-etl --follow --region eu-west-3
```

RÃ©sultat attendu :
```
INFO - -- DÃ©but du pipeline du projet Forecast 2.0. --
INFO - [Ã‰tape 1/3] : EXTRACTION - Connexion Ã  S3...
INFO - âœ… 3 fichier(s) tÃ©lÃ©chargÃ©(s) depuis S3
INFO - [Ã‰tape 2/3] : TRANSFORMATION - Nettoyage et validation...
INFO - ğŸ“Š RÃ©sumÃ© transformation :
INFO -    - Fichiers traitÃ©s : 3
INFO -    - Mesures mÃ©tÃ©o    : 3807
INFO -    - Stations rÃ©f.    : 4
INFO -    - Total documents  : 3811
INFO - [Ã‰tape 3/3] : CHARGEMENT - Insertion dans MongoDB...
INFO - MongoConnector initialisÃ© en mode: Atlas
INFO - Connexion rÃ©ussie (Atlas) Ã  la base 'greenandcoop_weather'
INFO - Index MongoDB vÃ©rifiÃ©s/crÃ©Ã©s sur 'weather_data'.
INFO - -> SuccÃ¨s : 3811 documents insÃ©rÃ©s dans 'weather_data'
INFO -    (Mesures: 3807, Stations: 4)
INFO - === Pipeline terminÃ© avec succÃ¨s ! ===
```

---

## ğŸ“ˆ Reporting et mÃ©triques

### Temps d'exÃ©cution du pipeline

| Ã‰tape | DurÃ©e | Performance |
|-------|-------|-------------|
| Extraction S3 | ~0.6s | âœ… Excellent |
| Transformation | ~0.3s | âœ… Excellent |
| Connexion MongoDB | ~0.2s | âœ… Excellent |
| Insertion donnÃ©es | ~0.1s | âœ… Excellent |
| **Total pipeline** | **~1.2s** | âœ… Excellent |

### QualitÃ© des donnÃ©es

| MÃ©trique | Valeur | Seuil | Statut |
|----------|--------|-------|--------|
| Documents traitÃ©s | 3811 | - | - |
| Documents valides | 3811 | - | - |
| Documents rejetÃ©s | 0 | <1% | âœ… |
| **Taux d'erreur** | **0%** | <1% | âœ… |

### Temps d'accessibilitÃ© (MongoDB Atlas)

| RequÃªte | Temps | Seuil | Statut |
|---------|-------|-------|--------|
| Lecture unitaire (dernier relevÃ©) | ~2ms | <50ms | âœ… |
| Filtrage par type | ~5ms | <50ms | âœ… |
| Filtrage par station | ~3ms | <50ms | âœ… |
| AgrÃ©gation (moyenne tempÃ©rature) | ~15ms | <100ms | âœ… |
| RequÃªte gÃ©ographique | ~10ms | <100ms | âœ… |

### Scripts de reporting

```bash
# Mesurer la performance (depuis le conteneur ou en local)
python -m src.reporting.check_performance

# VÃ©rifier la qualitÃ© des donnÃ©es
python -m src.reporting.check_quality

# Tester la rÃ©plication (environnement local uniquement)
python -m src.reporting.test_replication
```

---

## ğŸ“ Structure du projet

```
greenandcoop-forecast/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                    # Ce fichier
â”œâ”€â”€ ğŸ“„ Dockerfile                   # Image Docker du pipeline
â”œâ”€â”€ ğŸ“„ docker-compose.yml           # Environnement local (ReplicaSet)
â”œâ”€â”€ ğŸ“„ requirements.txt             # DÃ©pendances Python
â”‚
â”œâ”€â”€ ğŸ“ config/
â”‚   â””â”€â”€ ğŸ“„ .env                     # Variables d'environnement
â”‚
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”œâ”€â”€ ğŸ“„ main.py                  # Point d'entrÃ©e du pipeline
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ connectors/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ s3_connector.py      # Connexion AWS S3
â”‚   â”‚   â””â”€â”€ ğŸ“„ mongo_connector.py   # Connexion MongoDB (Atlas/Local)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ processing/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ cleaner.py           # Transformation des donnÃ©es
â”‚   â”‚   â””â”€â”€ ğŸ“„ validator.py         # Validation Pydantic (schÃ©ma unifiÃ©)
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ reporting/
â”‚       â”œâ”€â”€ ğŸ“„ check_performance.py # Mesure temps d'accÃ¨s
â”‚       â”œâ”€â”€ ğŸ“„ check_quality.py     # Audit qualitÃ© donnÃ©es
â”‚       â””â”€â”€ ğŸ“„ test_replication.py  # Test rÃ©plication (local)
â”‚
â”œâ”€â”€ ğŸ“ tests/
â”‚   â””â”€â”€ ğŸ“„ test_quality.py          # Tests unitaires pytest
â”‚
â”œâ”€â”€ ğŸ“ docs/
â”‚   â”œâ”€â”€ ğŸ“„ TRANSFORMATION_LOGIC.md  # Logique de transformation
â”‚   â”œâ”€â”€ ğŸ“„ MIGRATION_LOGIC.md       # Logique de migration
â”‚   â”œâ”€â”€ ğŸ“„ DEPLOYMENT_FLOW.md       # Logigramme de dÃ©ploiement
â”‚   â””â”€â”€ ğŸ“ diagrams/                # Diagrammes exportÃ©s
â”‚
â”œâ”€â”€ ğŸ“ ecs-deployment/              # Fichiers dÃ©ploiement AWS
â”‚   â”œâ”€â”€ ğŸ“„ task-definition.json
â”‚   â”œâ”€â”€ ğŸ“„ trust-policy.json
â”‚   â””â”€â”€ ğŸ“„ s3-access-policy.json
â”‚
â””â”€â”€ ğŸ“ logs/                        # Logs locaux
    â””â”€â”€ ğŸ“„ pipeline.log
```

---

## ğŸ“ Contact

**Projet** : Forecast 2.0 - GreenAndCoop  
**Chef de projet** : Ouly (Data Science)  
**Data Engineer** : [Votre nom]  
**Date** : DÃ©cembre 2024

---

## ğŸ“š Documentation complÃ©mentaire

- [Logique de transformation](docs/TRANSFORMATION_LOGIC.md)
- [Logique de migration](docs/MIGRATION_LOGIC.md)
- [Logigramme de dÃ©ploiement](docs/DEPLOYMENT_FLOW.md)
- [Commandes AWS](AWS_COMMANDS.md)
- [AWS ECS Documentation](https://docs.aws.amazon.com/ecs/)
- [MongoDB Atlas Documentation](https://docs.atlas.mongodb.com/)
