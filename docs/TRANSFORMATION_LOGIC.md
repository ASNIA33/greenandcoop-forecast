# üîÑ Logique de Transformation des Donn√©es

Ce document d√©crit en d√©tail le processus de transformation des donn√©es brutes issues de S3 vers un format normalis√© compatible avec MongoDB.

---

## üìã Table des mati√®res

1. [Vue d'ensemble](#-vue-densemble)
2. [Sources de donn√©es](#-sources-de-donn√©es)
3. [Processus de transformation](#-processus-de-transformation)
4. [R√®gles de conversion](#-r√®gles-de-conversion)
5. [Validation des donn√©es](#-validation-des-donn√©es)
6. [Gestion des erreurs](#-gestion-des-erreurs)
7. [Scripts concern√©s](#-scripts-concern√©s)

---

## üéØ Vue d'ensemble

### Objectifs

1. **Uniformiser** les donn√©es provenant de sources h√©t√©rog√®nes (Weather Underground, InfoClimat)
2. **Convertir** les unit√©s de mesure vers le syst√®me m√©trique international
3. **Valider** les donn√©es selon un sch√©ma strict (Pydantic)
4. **Enrichir** les mesures avec les m√©tadonn√©es des stations

### Flux de transformation

```mermaid
flowchart LR
    subgraph INPUT["üì• Entr√©e"]
        S3["S3 Bucket<br/>Fichiers JSONL"]
    end
    
    subgraph TRANSFORM["üîÑ Transformation"]
        LOAD["Chargement<br/>JSONL ‚Üí DataFrame"]
        MAP["Mapping<br/>colonnes"]
        CONV["Conversions<br/>unit√©s"]
        META["Enrichissement<br/>m√©tadonn√©es"]
        VALID["Validation<br/>Pydantic"]
    end
    
    subgraph OUTPUT["üì§ Sortie"]
        MEAS["measurements[]"]
        STAT["stations[]"]
    end
    
    S3 --> LOAD --> MAP --> CONV --> META --> VALID
    VALID --> MEAS
    VALID --> STAT
```

---

## üì° Sources de donn√©es

### Fichiers trait√©s

| Fichier | Source | Type | Contenu |
|---------|--------|------|---------|
| `station_ichtegem_BE.jsonl` | Weather Underground | Mesures | Relev√©s m√©t√©o Ichtegem (Belgique) |
| `station_la_madelaine_FR.jsonl` | Weather Underground | Mesures | Relev√©s m√©t√©o La Madeleine (France) |
| `stations_info_climat.jsonl` | InfoClimat | Stations | M√©tadonn√©es stations Hauts-de-France |

### Format d'entr√©e (Airbyte JSONL)

Les fichiers g√©n√©r√©s par Airbyte ont la structure suivante :

```json
{"_airbyte_data": {"Time": "12:00 AM", "Temperature": "57.0 ¬∞F", "Humidity": "87 %", ...}}
{"_airbyte_data": {"Time": "12:10 AM", "Temperature": "56.8 ¬∞F", "Humidity": "88 %", ...}}
```

### M√©tadonn√©es des stations (hardcod√©es)

Les m√©tadonn√©es des stations Weather Underground sont d√©finies dans le script :

```python
STATION_METADATA = {
    "station_la_madelaine_FR.jsonl": {
        "station_id": "ILAMAD25",
        "station_name": "La Madeleine",
        "city": "La Madeleine",
        "latitude": 50.659,
        "longitude": 3.07,
        "elevation": 23
    },
    "station_ichtegem_BE.jsonl": {
        "station_id": "IICHTE19",
        "station_name": "WeerstationBS",
        "city": "Ichtegem",
        "latitude": 51.092,
        "longitude": 2.999,
        "elevation": 15
    }
}
```

---

## üîÑ Processus de transformation

### √âtape 1 : Chargement des fichiers JSONL

```python
def load_airbyte_jsonl(file_path: str) -> pd.DataFrame:
    """
    Lit un fichier JSONL g√©n√©r√© par Airbyte.
    Extrait le contenu de '_airbyte_data' pour chaque ligne.
    """
    data_list = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            record = json.loads(line)
            if '_airbyte_data' in record:
                data_list.append(record['_airbyte_data'])
    return pd.DataFrame(data_list)
```

### √âtape 2 : Mapping des colonnes

Les colonnes brutes sont renomm√©es vers un sch√©ma standardis√© :

| Colonne source | Colonne cible | Description |
|----------------|---------------|-------------|
| `Time` | `time_str` | Heure du relev√© (string) |
| `Temperature` | `temp_raw` | Temp√©rature brute (¬∞F) |
| `Humidity` | `humidity_percent` | Humidit√© relative (%) |
| `Dew Point` | `dew_point` | Point de ros√©e |
| `Wind` | `wind_direction` | Direction du vent |
| `Speed` | `wind_speed_raw` | Vitesse du vent (mph) |
| `Gust` | `wind_gust_raw` | Rafales (mph) |
| `Pressure` | `pressure_inHg` | Pression (inHg) |
| `Precip. Rate.` | `precip_rate` | Taux de pr√©cipitation |
| `Precip. Accum.` | `precip_accum` | Cumul de pr√©cipitation |

### √âtape 3 : Conversions d'unit√©s

```python
def fahrenheit_to_celsius(f):
    """Convertit Fahrenheit vers Celsius."""
    if f is None: return None
    return round((f - 32) * 5.0/9.0, 2)

def mph_to_kmh(mph):
    """Convertit miles/heure vers km/heure."""
    if mph is None: return None
    return round(mph * 1.60934, 2)

def inHg_to_hPa(inHg):
    """Convertit pouces de mercure vers hectopascals."""
    if inHg is None: return None
    return round(inHg * 33.8639, 1)
```

### √âtape 4 : Enrichissement des m√©tadonn√©es

Chaque mesure est enrichie avec les informations de la station :

```python
for key, value in STATION_METADATA[filename].items():
    df[key] = value
```

R√©sultat : Chaque ligne contient `station_id`, `station_name`, `latitude`, `longitude`, `elevation`.

### √âtape 5 : Construction du timestamp

```python
# Combinaison date du jour + heure du relev√©
today_str = pd.Timestamp.now().strftime('%Y-%m-%d')
df['timestamp'] = pd.to_datetime(today_str + ' ' + df['time_str'].astype(str))

# Ajout d'un offset pour diff√©rencier les relev√©s de m√™me heure
df['timestamp'] = df['timestamp'] + pd.to_timedelta(df.index, unit='s')
```

---

## üìè R√®gles de conversion

### Tableau r√©capitulatif

| Mesure | Unit√© source | Unit√© cible | Formule |
|--------|--------------|-------------|---------|
| Temp√©rature | ¬∞F | ¬∞C | `(F - 32) √ó 5/9` |
| Vitesse du vent | mph | km/h | `mph √ó 1.60934` |
| Pression | inHg | hPa | `inHg √ó 33.8639` |
| Humidit√© | % | % | Aucune (nettoyage) |

### Nettoyage des valeurs

```python
def clean_value(val):
    """
    Nettoie une valeur brute :
    - G√®re les NaN et valeurs vides
    - Extrait les nombres des cha√Ænes (ex: "57.0 ¬∞F" ‚Üí 57.0)
    """
    if pd.isna(val) or val == "":
        return None
    if isinstance(val, (int, float)):
        return float(val)
    # Extraction du nombre via regex
    match = re.search(r"[-+]?\d*\.\d+|\d+", str(val))
    if match:
        return float(match.group())
    return None
```

---

## ‚úÖ Validation des donn√©es

### Sch√©ma Pydantic

Les donn√©es sont valid√©es via un mod√®le Pydantic strict :

```python
from pydantic import BaseModel, Field, field_validator

class WeatherMeasurement(BaseModel):
    station_id: str                                      # Requis
    station_name: Optional[str] = None
    timestamp: datetime                                  # Requis
    
    # R√®gles de validation strictes
    temperature_celsius: float = Field(ge=-60, le=60)    # -60¬∞C √† +60¬∞C
    humidity_percent: Optional[float] = Field(None, ge=0, le=100)
    wind_speed_kmh: Optional[float] = Field(None, ge=0)  # Pas de vent n√©gatif
    pressure_hpa: Optional[float] = Field(None, ge=800, le=1200)
    latitude: Optional[float] = None
    longitude: Optional[float] = None
```

### R√®gles de validation

| Champ | R√®gle | Motif de rejet |
|-------|-------|----------------|
| `station_id` | Requis, non vide | `station_id: Field required` |
| `timestamp` | Requis, type datetime | `timestamp: Invalid datetime` |
| `temperature_celsius` | -60 ‚â§ T ‚â§ +60 | `temperature_celsius: greater than or equal to -60` |
| `humidity_percent` | 0 ‚â§ H ‚â§ 100 | `humidity_percent: less than or equal to 100` |
| `wind_speed_kmh` | ‚â• 0 | `wind_speed_kmh: greater than or equal to 0` |
| `pressure_hpa` | 800 ‚â§ P ‚â§ 1200 | `pressure_hpa: Input should be >= 800` |

### Gestion des NaN

```python
@field_validator('temperature_celsius', 'humidity_percent', 'wind_speed_kmh', mode='before')
@classmethod
def handle_nan(cls, v):
    """Convertit les NaN pandas en None Python."""
    if pd.isna(v) or v == "":
        return None
    return v
```

---

## ‚ö†Ô∏è Gestion des erreurs

### Documents rejet√©s

Les documents qui √©chouent √† la validation sont :
1. **Logg√©s** avec le motif de rejet
2. **Exclus** du chargement MongoDB
3. **Comptabilis√©s** pour le taux d'erreur

```python
def validate_data(records: list) -> tuple:
    """
    Valide une liste d'enregistrements via Pydantic.
    Retourne (valid_records, rejected_records).
    """
    valid_records = []
    rejected_records = []

    for record in records:
        try:
            measurement = WeatherMeasurement(**record)
            valid_records.append(measurement.model_dump())
        except ValidationError as e:
            error_messages = [f"{err['loc'][0]}: {err['msg']}" for err in e.errors()]
            record['rejection_reason'] = "; ".join(error_messages)
            rejected_records.append(record)

    return valid_records, rejected_records
```

### Exemple de log

```
2025-12-24 15:18:21 - WARNING - Validation M√©t√©o : 3 lignes rejet√©es dans station_ichtegem_BE.jsonl.
2025-12-24 15:18:21 - WARNING - Exemple motif : temperature_celsius: Input should be less than or equal to 60
```

### Taux d'erreur actuel

| M√©trique | Valeur |
|----------|--------|
| Documents trait√©s | 3811 |
| Documents valides | 3811 |
| Documents rejet√©s | 0 |
| **Taux d'erreur** | **0%** |

---

## üìÅ Scripts concern√©s

### Fichiers

| Script | R√¥le |
|--------|------|
| `src/processing/cleaner.py` | Transformation et nettoyage |
| `src/processing/validator.py` | Validation Pydantic |
| `src/connectors/s3_connector.py` | T√©l√©chargement depuis S3 |

### Fonctions principales

```python
# cleaner.py
process_file(file_path, filename)      # Routeur principal
transform_weather_data(file_path, filename)  # Transformation mesures m√©t√©o
transform_infoclimat(file_path)        # Transformation stations InfoClimat
load_airbyte_jsonl(file_path)          # Lecture JSONL
clean_value(val)                       # Nettoyage valeurs
fahrenheit_to_celsius(f)               # Conversion ¬∞F ‚Üí ¬∞C
mph_to_kmh(mph)                        # Conversion mph ‚Üí km/h

# validator.py
validate_data(records)                 # Validation Pydantic
WeatherMeasurement                     # Mod√®le de validation
```

---

## üîó Documents li√©s

- [Logique de Migration](MIGRATION_LOGIC.md) - Chargement dans MongoDB
- [README Principal](../README.md) - Vue d'ensemble du projet

---

