# üöÄ Logique de Migration vers MongoDB

Ce document d√©crit le processus de chargement des donn√©es transform√©es dans MongoDB, l'architecture de la base de donn√©es, et les mesures de s√©curit√© mises en place.

---

## üìã Table des mati√®res

1. [Vue d'ensemble](#-vue-densemble)
2. [Architecture MongoDB](#-architecture-mongodb)
3. [Sch√©ma de la collection unifi√©e](#-sch√©ma-de-la-collection-unifi√©e)
4. [Processus de migration](#-processus-de-migration)
5. [Gestion de l'idempotence](#-gestion-de-lidempotence)
6. [S√©curit√© et r√©plication](#-s√©curit√©-et-r√©plication)
7. [Modes de connexion](#-modes-de-connexion)
8. [Monitoring et logs](#-monitoring-et-logs)
9. [Scripts concern√©s](#-scripts-concern√©s)

---

## üéØ Vue d'ensemble

### Objectifs

1. **Charger** les donn√©es transform√©es dans MongoDB de mani√®re fiable
2. **Garantir** l'idempotence (pas de doublons lors de r√©-ex√©cutions)
3. **Assurer** la haute disponibilit√© via un ReplicaSet
4. **S√©curiser** les acc√®s avec authentification et chiffrement

### Sch√©ma unifi√©

Le projet utilise une **collection unique `weather_data`** avec un champ discriminant `record_type` :

| record_type | Description | Documents |
|-------------|-------------|-----------|
| `measurement` | Relev√©s m√©t√©orologiques | 3807 |
| `station_reference` | M√©tadonn√©es InfoClimat | 4 |
| **Total** | | **3811** |

### Flux de migration

```mermaid
flowchart LR
    subgraph INPUT["üì• Entr√©e"]
        DATA["all_documents[]<br/>3811 documents<br/>(measurements + stations)"]
    end
    
    subgraph CONNECT["üîå Connexion"]
        URI["D√©tection mode<br/>Atlas / Local"]
        AUTH["Authentification<br/>User + Password"]
    end
    
    subgraph LOAD["üì§ Chargement"]
        IDX["Cr√©ation index"]
        INS["insert_many()<br/>ordered=False"]
        DUP["Gestion doublons"]
    end
    
    subgraph DB["üóÑÔ∏è MongoDB"]
        COL["Collection unique<br/>weather_data"]
    end
    
    DATA --> URI --> AUTH --> IDX --> INS --> DUP --> COL
```

---

## üèóÔ∏è Architecture MongoDB

### Environnement de production (AWS)

```mermaid
flowchart TB
    subgraph AWS["‚òÅÔ∏è AWS ECS"]
        ECS["üê≥ Container ETL<br/>forecast-etl"]
    end
    
    subgraph ATLAS["üåç MongoDB Atlas"]
        subgraph RS["ReplicaSet rs0"]
            P["üü¢ PRIMARY<br/>√âcritures"]
            S1["üîµ SECONDARY<br/>R√©plication"]
            S2["üîµ SECONDARY<br/>R√©plication"]
        end
        
        subgraph SECURITY["S√©curit√©"]
            TLS["üîí TLS/SSL"]
            AUTH["üîë Auth SCRAM"]
            NET["üåê Network Access"]
        end
    end
    
    ECS -->|"mongodb+srv://"| P
    P --> S1
    P --> S2
```

**Caract√©ristiques Atlas M0 (Gratuit)** :
- 3 n≈ìuds ReplicaSet (1 PRIMARY + 2 SECONDARY)
- 512 MB de stockage
- Chiffrement at-rest et in-transit
- Sauvegardes automatiques
- Failover automatique (~30s)

### Environnement de d√©veloppement (Local)

```mermaid
flowchart TB
    subgraph DOCKER["üê≥ Docker Compose"]
        ETL["forecast-etl<br/>Container Python"]
        
        subgraph RS["ReplicaSet rs0"]
            M1["mongo1:27017<br/>PRIMARY"]
            M2["mongo2:27017<br/>SECONDARY"]
            ARB["mongo-arbiter:27017<br/>ARBITER"]
        end
        
        INIT["mongo-init<br/>rs.initiate()"]
    end
    
    ETL --> M1
    M1 --> M2
    M1 --> ARB
    INIT --> M1
```

---

## üìä Sch√©ma de la collection unifi√©e

### Collection `weather_data`

Une collection unique stocke **tous les types de documents** avec un champ discriminant `record_type`.

### Document type `measurement` (relev√©s m√©t√©o)

```javascript
{
    "_id": ObjectId("..."),
    "record_type": "measurement",
    "station_id": "IICHTE19",
    "station_name": "WeerstationBS",
    "source": "weather_underground",
    "location": {
        "city": "Ichtegem",
        "country": "BE",
        "latitude": 51.092,
        "longitude": 2.999,
        "elevation": 15
    },
    "timestamp": ISODate("2025-12-24T00:04:00Z"),
    "measurements": {
        "temperature_celsius": 13.78,
        "humidity_percent": 87,
        "wind_speed_kmh": 13.2,
        "pressure_hpa": 998.3
    }
}
```

### Document type `station_reference` (m√©tadonn√©es)

```javascript
{
    "_id": ObjectId("..."),
    "record_type": "station_reference",
    "station_id": "00052",
    "station_name": "Armenti√®res",
    "source": "infoclimat",
    "location": {
        "city": "Armenti√®res",
        "country": "FR",
        "latitude": 50.689,
        "longitude": 2.877,
        "elevation": 16
    },
    "station_type": "static",
    "license": {
        "name": "CC BY",
        "url": "https://creativecommons.org/licenses/by/2.0/fr/",
        "source_url": "https://www.infoclimat.fr/stations/metadonnees.php?id=00052"
    },
    "timestamp": ISODate("2025-12-24T15:18:22Z")
}
```

### Diagramme ERD

```mermaid
erDiagram
    WEATHER_DATA {
        ObjectId _id PK
        string record_type "measurement | station_reference"
        string station_id "Identifiant station"
        string station_name "Nom de la station"
        string source "weather_underground | infoclimat"
        object location "Localisation g√©ographique"
        datetime timestamp "Date/heure"
        object measurements "Mesures m√©t√©o (si measurement)"
        string station_type "Type station (si station_ref)"
        object license "Licence (si station_reference)"
    }
    
    LOCATION {
        string city "Ville"
        string country "Pays"
        float latitude "Latitude GPS"
        float longitude "Longitude GPS"
        int elevation "Altitude"
    }
    
    MEASUREMENTS {
        float temperature_celsius "Temp√©rature"
        float humidity_percent "Humidit√©"
        float wind_speed_kmh "Vent"
        float pressure_hpa "Pression"
    }
    
    LICENSE {
        string name "Nom licence"
        string url "URL licence"
        string source_url "URL source"
    }
    
    WEATHER_DATA ||--|| LOCATION : "contient"
    WEATHER_DATA ||--o| MEASUREMENTS : "si measurement"
    WEATHER_DATA ||--o| LICENSE : "si station_reference"
```

### Avantages du sch√©ma unifi√©

| Avantage | Description |
|----------|-------------|
| **Pas de jointures** | MongoDB n'est pas optimis√© pour `$lookup` |
| **Requ√™tes simples** | Filtrage par `record_type` suffit |
| **Documents auto-portants** | Toutes les infos dans un seul document |
| **Flexibilit√©** | Ajout de nouveaux `record_type` facile |

---

## ‚öôÔ∏è Processus de migration

### √âtape 1 : Connexion

```python
def connect(self):
    """√âtablissement de la connexion MongoDB."""
    self.client = MongoClient(self.uri, serverSelectionTimeoutMS=30000)
    self.client.admin.command('ping')  # Test de connexion
    self.db = self.client[self.db_name]
    logger.info(f"Connexion r√©ussie ({self.mode}) √† la base '{self.db_name}'")
```

### √âtape 2 : Cr√©ation des index

```python
def init_db(self):
    """Cr√©e les index pour la collection unifi√©e."""
    collection = self.db["weather_data"]
    
    # Index 1 : Recherche par station et date
    collection.create_index(
        [("station_id", ASCENDING), ("timestamp", ASCENDING)],
        name="idx_station_timestamp"
    )
    
    # Index 2 : Filtrage par type de document
    collection.create_index(
        [("record_type", ASCENDING)],
        name="idx_record_type"
    )
    
    # Index 3 : Recherche par source
    collection.create_index(
        [("source", ASCENDING)],
        name="idx_source"
    )
    
    # Index 4 : Unicit√© pour les stations de r√©f√©rence
    collection.create_index(
        [("record_type", ASCENDING), ("station_id", ASCENDING), ("source", ASCENDING)],
        unique=True,
        partialFilterExpression={"record_type": "station_reference"},
        name="idx_unique_station_reference"
    )
```

### √âtape 3 : Insertion des documents

```python
def insert_documents(self, data_list: list):
    """
    Ins√®re les documents dans la collection unifi√©e.
    ordered=False : Continue m√™me si un document √©choue (doublon).
    """
    collection = self.db["weather_data"]
    result = collection.insert_many(data_list, ordered=False)
    
    # Statistiques par type
    measurements = sum(1 for d in data_list if d.get('record_type') == 'measurement')
    stations = sum(1 for d in data_list if d.get('record_type') == 'station_reference')
    
    logger.info(f"Succ√®s : {len(result.inserted_ids)} documents ins√©r√©s")
    logger.info(f"   (Mesures: {measurements}, Stations: {stations})")
    
    return len(result.inserted_ids)
```

### √âtape 4 : Fermeture

```python
def close(self):
    """Ferme proprement la connexion."""
    if self.client:
        self.client.close()
        logger.info("Connexion MongoDB ferm√©e.")
```

---

## üîÑ Gestion de l'idempotence

### Probl√©matique

Le pipeline peut √™tre ex√©cut√© plusieurs fois (re-run, debug, cron). Il ne doit **jamais** cr√©er de doublons.

### Solution : `ordered=False` + Gestion des erreurs

```python
try:
    result = collection.insert_many(data_list, ordered=False)
    count = len(result.inserted_ids)
    logger.info(f"Succ√®s : {count} documents ins√©r√©s")
    
except BulkWriteError as bwe:
    # Certains documents ont √©chou√© (doublons)
    inserted_count = bwe.details['nInserted']
    duplicates_count = len(bwe.details['writeErrors'])
    logger.info(f"Insertion : {inserted_count} ajout√©s, {duplicates_count} doublons ignor√©s")
```

### Comportement

| Sc√©nario | R√©sultat |
|----------|----------|
| 1√®re ex√©cution | 3811 documents ins√©r√©s |
| 2√®me ex√©cution (m√™mes donn√©es) | 0 insertions, 3811 doublons ignor√©s |
| 3√®me ex√©cution (donn√©es + nouvelles) | Seulement les nouvelles ins√©r√©es |

---

## üîí S√©curit√© et r√©plication

### Authentification

| Environnement | M√©thode | Stockage credentials |
|---------------|---------|---------------------|
| **Atlas (Prod)** | SCRAM-SHA-256 | Variable `MONGO_URI` dans Task Definition ECS |
| **Local (Dev)** | SCRAM-SHA-256 | Fichier `config/.env` |

### Chiffrement

| Type | Atlas | Local |
|------|-------|-------|
| **In-transit (TLS)** | ‚úÖ Automatique | ‚ùå Non configur√© |
| **At-rest** | ‚úÖ Automatique | ‚ùå Non configur√© |

### R√©seau

**MongoDB Atlas** :
- Network Access configur√© sur `0.0.0.0/0` (d√©veloppement)
- En production : restreindre aux IPs ECS/VPC

**AWS Security Group** :
```bash
# Trafic sortant autoris√©
IpProtocol: -1 (tout)
CidrIp: 0.0.0.0/0
```

### R√©plication (ReplicaSet)

```mermaid
sequenceDiagram
    participant App as ECS Container
    participant P as PRIMARY
    participant S1 as SECONDARY 1
    participant S2 as SECONDARY 2
    
    App->>P: insert_many()
    P->>P: √âcriture locale
    P-->>S1: R√©plication async
    P-->>S2: R√©plication async
    P->>App: Acknowledgment
    
    Note over P,S2: R√©plication < 100ms
    
    alt PRIMARY tombe
        S1->>S1: √âlection
        S1->>S1: Devient PRIMARY
        Note over S1: Failover ~30s
    end
```

### Avantages du ReplicaSet

| Fonctionnalit√© | Description |
|----------------|-------------|
| **Haute disponibilit√©** | Failover automatique si le PRIMARY tombe |
| **Durabilit√©** | Donn√©es r√©pliqu√©es sur 3 n≈ìuds |
| **Lecture distribu√©e** | Possibilit√© de lire sur les SECONDARY |
| **Sauvegardes** | Snapshots sans impact sur le PRIMARY |

---

## üîå Modes de connexion

### D√©tection automatique

```python
def __init__(self):
    # Priorit√© 1 : URI Atlas compl√®te
    atlas_uri = os.getenv("MONGO_URI")
    
    if atlas_uri:
        self.uri = atlas_uri
        self.mode = "Atlas"
    else:
        # Priorit√© 2 : Variables s√©par√©es (Docker Compose)
        user = os.getenv("MONGO_INITDB_ROOT_USERNAME")
        pwd = os.getenv("MONGO_INITDB_ROOT_PASSWORD")
        host = os.getenv("MONGO_HOST", "localhost")
        port = os.getenv("MONGO_PORT", "27017")
        rs_name = os.getenv("MONGO_REPLICA_SET")
        
        if rs_name:
            self.uri = f"mongodb://{user}:{pwd}@{host}:{port}/?authSource=admin&replicaSet={rs_name}"
            self.mode = "ReplicaSet"
        else:
            self.uri = f"mongodb://{user}:{pwd}@{host}:{port}/?authSource=admin&directConnection=true"
            self.mode = "Standalone"
```

### Configurations

| Mode | Variable(s) | URI g√©n√©r√©e |
|------|-------------|-------------|
| **Atlas** | `MONGO_URI` | `mongodb+srv://user:pwd@cluster.mongodb.net/...` |
| **ReplicaSet Local** | `MONGO_HOST`, `MONGO_REPLICA_SET` | `mongodb://user:pwd@host:port/?replicaSet=rs0` |
| **Standalone** | `MONGO_HOST` (sans RS) | `mongodb://user:pwd@host:port/?directConnection=true` |

### Variables d'environnement

```bash
# Mode Atlas (Production - ECS)
MONGO_URI=mongodb+srv://forecast_user:xxx@forecast-cluster.meeiptz.mongodb.net/?appName=forecast-cluster
MONGO_DB_NAME=greenandcoop_weather

# Mode Local (D√©veloppement - Docker Compose)
MONGO_INITDB_ROOT_USERNAME=admin
MONGO_INITDB_ROOT_PASSWORD=password123
MONGO_HOST=mongo1
MONGO_PORT=27017
MONGO_REPLICA_SET=rs0
MONGO_DB_NAME=greenandcoop_weather
```

---

## üìä Monitoring et logs

### Logs du pipeline

```
INFO - -- D√©but du pipeline du projet Forecast 2.0. --
INFO - [√âtape 1/3] : EXTRACTION - Connexion √† S3...
INFO - ‚úÖ 3 fichier(s) t√©l√©charg√©(s) depuis S3
INFO - [√âtape 2/3] : TRANSFORMATION - Nettoyage et validation...
INFO - üìä R√©sum√© transformation :
INFO -    - Fichiers trait√©s : 3
INFO -    - Mesures m√©t√©o    : 3807
INFO -    - Stations r√©f.    : 4
INFO -    - Total documents  : 3811
INFO - [√âtape 3/3] : CHARGEMENT - Insertion dans MongoDB...
INFO - MongoConnector initialis√© en mode: Atlas
INFO - Connexion r√©ussie (Atlas) √† la base 'greenandcoop_weather'
INFO - Index MongoDB v√©rifi√©s/cr√©√©s sur 'weather_data'.
INFO - -> Succ√®s : 3811 documents ins√©r√©s dans 'weather_data'
INFO -    (Mesures: 3807, Stations: 4)
INFO - üìä Statistiques MongoDB (weather_data) :
INFO -    - Total documents      : 3811
INFO -    - Mesures m√©t√©o        : 3807
INFO -    - Stations r√©f√©rence   : 4
INFO - === Pipeline termin√© avec succ√®s ! ===
```

### M√©triques de performance

| M√©trique | Valeur | M√©thode de mesure |
|----------|--------|-------------------|
| Temps de connexion | ~200ms | Logs pipeline |
| Temps d'insertion (3811 docs) | ~100ms | Logs pipeline |
| Temps lecture unitaire | ~2ms | `check_performance.py` |
| Temps filtrage par type | ~5ms | `check_performance.py` |
| Temps agr√©gation | ~15ms | `check_performance.py` |

### Monitoring Atlas

Accessible via [cloud.mongodb.com](https://cloud.mongodb.com) :
- **Metrics** : CPU, RAM, IOPS, connexions
- **Real-Time Performance** : Requ√™tes lentes
- **Alerts** : Notifications email/Slack

### Monitoring CloudWatch (ECS)

```bash
# Logs en temps r√©el
aws logs tail /ecs/forecast-etl --follow --region eu-west-3

# Recherche d'erreurs
aws logs filter-log-events \
    --log-group-name /ecs/forecast-etl \
    --filter-pattern "ERROR" \
    --region eu-west-3
```

---

## üìÅ Scripts concern√©s

### Fichiers

| Script | R√¥le |
|--------|------|
| `src/connectors/mongo_connector.py` | Connexion et op√©rations MongoDB |
| `src/main.py` | Orchestration du pipeline |
| `src/reporting/check_quality.py` | Audit qualit√© des donn√©es |
| `src/reporting/check_performance.py` | Mesure temps d'acc√®s |
| `src/reporting/test_replication.py` | Test du ReplicaSet |

### Classe MongoConnector

```python
class MongoConnector:
    COLLECTION_NAME = "weather_data"  # Collection unique
    
    def __init__(self):          # D√©tection mode + construction URI
    def connect(self):           # √âtablissement connexion
    def init_db(self):           # Cr√©ation des index
    def insert_documents(self, data_list):  # Insertion collection unifi√©e
    def get_stats(self):         # Statistiques par record_type
    def close(self):             # Fermeture connexion
```

---

## üìà R√©sultats de la migration

### Statistiques actuelles

| Type | Documents | Description |
|------|-----------|-------------|
| `measurement` | 3807 | Relev√©s m√©t√©orologiques |
| `station_reference` | 4 | M√©tadonn√©es InfoClimat |
| **Total** | **3811** | Collection `weather_data` |

### Qualit√© des donn√©es

| M√©trique | Valeur |
|----------|--------|
| Documents conformes | 3811 (100%) |
| Documents rejet√©s | 0 (0%) |
| Doublons d√©tect√©s | 0 |
| **Taux d'erreur** | **0%** |

---

## üîç Requ√™tes utiles

```javascript
// Compter par type
db.weather_data.aggregate([
    { $group: { _id: "$record_type", count: { $sum: 1 } } }
])

// Toutes les mesures m√©t√©o
db.weather_data.find({ record_type: "measurement" })

// Mesures d'une station sp√©cifique
db.weather_data.find({
    record_type: "measurement",
    station_id: "IICHTE19"
})

// Moyenne temp√©rature par station
db.weather_data.aggregate([
    { $match: { record_type: "measurement" } },
    { $group: {
        _id: "$station_id",
        avg_temp: { $avg: "$measurements.temperature_celsius" },
        count: { $sum: 1 }
    }}
])

// Toutes les stations de r√©f√©rence
db.weather_data.find({ record_type: "station_reference" })
```

---

## üîó Documents li√©s

- [Logique de Transformation](TRANSFORMATION_LOGIC.md) - Pr√©paration des donn√©es
- [README Principal](../README.md) - Vue d'ensemble du projet
- [Commandes AWS](../AWS_COMMANDS.md) - Guide CLI
- [Logigramme de d√©ploiement](DEPLOYMENT_FLOW.md) - Flux DevOps

---

**Projet Forecast 2.0** - GreenAndCoop  
Derni√®re mise √† jour : D√©cembre 2024
