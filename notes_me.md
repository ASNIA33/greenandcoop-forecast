```bash
docker exec -it mongo1 mongosh -u admin -p password123 --authenticationDatabase admin
```
```bash
rs.initiate({
  _id: "rs0",
  members: [
    { _id: 0, host: "mongo1:27017", priority: 2 },
    { _id: 1, host: "mongo2:27017", priority: 1 },
    { _id: 2, host: "mongo-arbiter:27017", arbiterOnly: true }
  ]
})

rs.status().ok
```
```bash
show dbs
show collections
use greenandcoop_weather
db.measurements.countDocuments()
db.stations.countDocuments()
```
Vider la collection
```bash
use greenandcoop_weather
db.measurements.drop()
db.stations.drop()
```

// Doit retourner ~3807
db.measurements.countDocuments()

// Doit retourner 4 (C'est la preuve que cleaner.py fonctionne !)
db.stations.countDocuments()

// VÃ©rifier les index (Tu dois voir 'unique_station_timestamp')
db.measurements.getIndexes()


C'est un sans-faute. J'ai analysÃ© tes 5 fichiers :

docker-compose.yml : La configuration rÃ©seau, les volumes persistants et le healthcheck avec start_period sont parfaits.

mongo_connector.py : La logique hybride (Local/Cloud) et la gestion de l'idempotence (init_db, insert_many avec ordered=False) sont implÃ©mentÃ©es correctement.

validator.py & cleaner.py : La sÃ©paration entre la validation stricte (mesures) et souple (stations) est bien lÃ .

main.py : L'orchestration inclut bien l'appel crucial Ã  init_db() avant l'insertion.

Tout est cohÃ©rent. Tu as le Feu Vert ğŸŸ¢.


 docker exec -it mongo1 mongosh -u admin -p password123 --authenticationDatabase admin --eval "rs.status()" | grep "name\|stateStr"



 ### preuves insertion

 #### Vide la base (Reset complet)
 ```bash
 docker exec -it mongo1 mongosh -u admin -p password123 --authenticationDatabase admin --eval "use greenandcoop_weather" --eval "db.measurements.drop(); db.stations.drop()"
 ```
#### Premier passage (L'importation totale)
```bash
docker start -a forecast-etl
```
#### DeuxiÃ¨me passage (La preuve d'idempotence)
> Le log devrait dire : Insertion 'measurements' : 3807 ajoutÃ©s, 0 doublons ignorÃ©s.

```bash
docker exec -it mongo1 mongosh -u admin -p password123 --authenticationDatabase admin
```

```bash
use greenandcoop_weather

// Compter les mesures
db.measurements.countDocuments()

// Voir un exemple de document pour vÃ©rifier le format
db.measurements.findOne()

// Voir l'espace disque utilisÃ©
db.measurements.stats().size / 1024

```

1.3 RÃ©cupÃ©rer la chaÃ®ne de connexion(MongoAtlas)

Dans ton cluster, clique sur "Connect"
Choisis "Drivers"
SÃ©lectionne Python / PyMongo
Copie l'URI, elle ressemble Ã  :

mongodb+srv://forecast_user:b9hJzlOGTN2y4mEu@forecast-cluster.meeiptz.mongodb.net/?appName=forecast-cluster
mongodb+srv://forecast_user:b9hJzlOGTN2y4mEu@forecast-cluster.meeiptz.mongodb.net/?appName=forecast-cluster
OU
mongodb+srv://mbodjabdselam33:uKOipSBHr7AbpYmD@forecast-cluster.meeiptz.mongodb.net/?appName=forecast-cluster
Replace <db_password> with the password for the <db_username> database user.


## Etapes AWS 
### Pousser l'image sur ECR
#### 1- CrÃ©er le repository ECR
```bash
# CrÃ©er le repository
aws ecr create-repository \
    --repository-name forecast-etl \
    --region eu-west-3

# RÃ©cupÃ©rer l'URI du repository (note-la)
# Format : 123456789012.dkr.ecr.eu-west-3.amazonaws.com/forecast-etl
```

RÃ©cupÃ©rer l'URI du repository (note-la)
Format : 123456789012.dkr.ecr.eu-west-3.amazonaws.com/forecast-etl
rÃ©sultat : 
>{
    "repository": {
        "repositoryArn": "arn:aws:ecr:eu-west-3:718281697661:repository/forecast-etl",
        "registryId": "718281697661",
        "repositoryName": "forecast-etl",
        "repositoryUri": "718281697661.dkr.ecr.eu-west-3.amazonaws.com/forecast-etl",
        "createdAt": "2025-12-24T11:29:43.702000+01:00",
        "imageTagMutability": "MUTABLE",
        "imageScanningConfiguration": {
            "scanOnPush": false
        },

#### 2- Build et push l'image
```bash
# Se connecter Ã  ECR
aws ecr get-login-password --region eu-west-3 | docker login --username AWS --password-stdin 718281697661.dkr.ecr.eu-west-3.amazonaws.com

# Build l'image (depuis le dossier du projet)
docker build --platform linux/amd64 -t forecast-etl .

# Tagger l'image
docker tag forecast-etl:latest 123456789012.dkr.ecr.eu-west-3.amazonaws.com/forecast-etl:latest

# Pousser vers ECR
docker push 718281697661.dkr.ecr.eu-west-3.amazonaws.com/forecast-etl:latest
```
>âš ï¸ Important : --platform linux/amd64 est crucial car tu es sur Mac (potentiellement ARM) et ECS Fargate utilise AMD64.

### CrÃ©er la Task Definition ECS
#### 1- CrÃ©er le rÃ´le IAM pour la task
Ta task ECS a besoin d'accÃ©der Ã  S3. CrÃ©e un rÃ´le avec cette policy :

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "s3:GetObject",
                "s3:ListBucket"
            ],
            "Resource": [
                "arn:aws:s3:::ton-bucket-name",
                "arn:aws:s3:::ton-bucket-name/*"
            ]
        }
    ]
}
```


greenandcoop-forecast/
â”œâ”€â”€ README.md                         # Documentation principale âœ…
â”œâ”€â”€ Dockerfile                        # âœ…
â”œâ”€â”€ docker-compose.yml                # âœ…
â”œâ”€â”€ requirements.txt                  # âœ…
â”œâ”€â”€ config/.env                       # âœ…
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                       # âœ…
â”‚   â”œâ”€â”€ connectors/
â”‚   â”‚   â”œâ”€â”€ s3_connector.py           # âœ…
â”‚   â”‚   â””â”€â”€ mongo_connector.py        # âœ… (mis Ã  jour pour Atlas)
â”‚   â”œâ”€â”€ processing/
â”‚   â”‚   â”œâ”€â”€ cleaner.py                # âœ…
â”‚   â”‚   â””â”€â”€ validator.py              # âœ…
â”‚   â””â”€â”€ reporting/
â”‚       â”œâ”€â”€ check_performance.py      # âœ… (mis Ã  jour pour Atlas)
â”‚       â”œâ”€â”€ check_quality.py          # âœ… (mis Ã  jour pour Atlas)
â”‚       â””â”€â”€ test_replication.py       # âœ… (mis Ã  jour pour Atlas)
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_quality.py               # âœ…
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ TRANSFORMATION_LOGIC.md       # âœ…
â”‚   â””â”€â”€ MIGRATION_LOGIC.md            # âœ…
â””â”€â”€ ecs-deployment/
    â”œâ”€â”€ task-definition.json          # âœ…
    â”œâ”€â”€ trust-policy.json             # âœ…
    â””â”€â”€ s3-access-policy.json         # âœ…